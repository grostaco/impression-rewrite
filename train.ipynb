{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "f:\\impression\\venv\\lib\\site-packages\\tqdm\\auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import tensorflow_text as _\n",
    "\n",
    "import tensorflow as tf\n",
    "import tensorflow_hub as hub\n",
    "from official.nlp import optimization  # to create AdamW optimizer\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "import json\n",
    "import numpy as np\n",
    "import pickle \n",
    "\n",
    "gpu = tf.config.list_physical_devices('GPU')\n",
    "tf.config.experimental.set_memory_growth(gpu[0], True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "export = json.load(open('assets/export_large.json', encoding='utf-8'))\n",
    "ds = [(x['author']['name'], x['content']) for x in export['messages']]\n",
    "tfhub_handle_encoder = \"https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-4_H-512_A-8/1\"\n",
    "tfhub_handle_preprocess = \"https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_classifier_model():\n",
    "    text_input = tf.keras.layers.Input(shape=(), dtype=tf.string, name='text')\n",
    "    preprocessing_layer = hub.KerasLayer(tfhub_handle_preprocess, name='preprocessing')\n",
    "    encoder_inputs = preprocessing_layer(text_input)\n",
    "    encoder = hub.KerasLayer(tfhub_handle_encoder, trainable=True, name='bert_encoder')\n",
    "    outputs = encoder(encoder_inputs)\n",
    "\n",
    "    net = outputs['pooled_output']\n",
    "    net = tf.keras.layers.Dropout(0.1)(net)\n",
    "    net = tf.keras.layers.Dense(6, activation='softmax', name='multi_classifier')(net)\n",
    "    return tf.keras.Model(text_input, net)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = build_classifier_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = OneHotEncoder(handle_unknown='ignore')\n",
    "\n",
    "labels = encoder.fit_transform([[x[0]] for x in ds]).toarray()\n",
    "messages = np.array([x[1] for x in ds])\n",
    "\n",
    "ds_size = len(labels)\n",
    "\n",
    "\n",
    "features = tf.data.Dataset.from_tensor_slices(messages)\n",
    "labels = tf.data.Dataset.from_tensor_slices(labels)\n",
    "train_ds = tf.data.Dataset.zip((features, labels)).batch(32)\n",
    "train_ds = train_ds.cache().prefetch(buffer_size=tf.data.AUTOTUNE)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = tf.keras.losses.CategoricalCrossentropy()\n",
    "metrics = tf.metrics.CategoricalAccuracy()\n",
    "\n",
    "epochs = 10\n",
    "steps_per_epoch = tf.data.experimental.cardinality(train_ds).numpy()\n",
    "num_train_steps = steps_per_epoch * epochs\n",
    "num_warmup_steps = int(0.1 * num_train_steps)\n",
    "\n",
    "init_lr = 3e-5\n",
    "optimizer = optimization.create_optimizer(init_lr=init_lr,\n",
    "                                            num_train_steps=num_train_steps,\n",
    "                                            num_warmup_steps=num_warmup_steps,\n",
    "                                            optimizer_type='adamw')\n",
    "\n",
    "model.compile(optimizer=optimizer, loss=loss, metrics=metrics)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "436/436 [==============================] - 205s 458ms/step - loss: 1.6367 - categorical_accuracy: 0.3714\n",
      "Epoch 2/10\n",
      "436/436 [==============================] - 196s 451ms/step - loss: 1.3735 - categorical_accuracy: 0.4868\n",
      "Epoch 3/10\n",
      "436/436 [==============================] - 191s 438ms/step - loss: 1.2485 - categorical_accuracy: 0.5285\n",
      "Epoch 4/10\n",
      "436/436 [==============================] - 176s 403ms/step - loss: 1.1465 - categorical_accuracy: 0.5682\n",
      "Epoch 5/10\n",
      "436/436 [==============================] - 179s 411ms/step - loss: 1.0604 - categorical_accuracy: 0.6017\n",
      "Epoch 6/10\n",
      "436/436 [==============================] - 172s 394ms/step - loss: 0.9878 - categorical_accuracy: 0.6308\n",
      "Epoch 7/10\n",
      "436/436 [==============================] - 175s 401ms/step - loss: 0.9136 - categorical_accuracy: 0.6610\n",
      "Epoch 8/10\n",
      "436/436 [==============================] - 187s 429ms/step - loss: 0.8662 - categorical_accuracy: 0.6816\n",
      "Epoch 9/10\n",
      "436/436 [==============================] - 183s 420ms/step - loss: 0.8176 - categorical_accuracy: 0.6999\n",
      "Epoch 10/10\n",
      "436/436 [==============================] - 173s 397ms/step - loss: 0.7862 - categorical_accuracy: 0.7143\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(x=train_ds, epochs=epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 56ms/step\n",
      "Predicted [['- MrChacocha -']] with confidence 47.20%\n"
     ]
    }
   ],
   "source": [
    "def make_prediction(t: str):\n",
    "    pred = model.predict([t])\n",
    "    r = np.argmax(pred)\n",
    "    mask = np.zeros(shape=(6,))\n",
    "    mask[r] = 1\n",
    "    return encoder.inverse_transform([mask]), pred[0][r]\n",
    "\n",
    "target, confidence = make_prediction(\"Spam\")\n",
    "print(f'Predicted {target} with confidence {confidence * 100:.2f}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.4 ('venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "16ea4e7868b4c12adc7a06b8da4c3646b3cad48182f5595b81b52bc7fe78593b"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
